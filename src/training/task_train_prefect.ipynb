{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09085b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import json\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import mlflow\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from etl import EDAdataset\n",
    "sys.path.append(os.path.abspath('..'))  # Ajusta la ruta según la ubicación de 'src'\n",
    "from utils.conexion import SQLConnection\n",
    "from feature_engineer import PreprocesadorTexto\n",
    "from prefect import flow, get_run_logger, task\n",
    "from prefect.artifacts import create_markdown_artifact, create_table_artifact\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score,\n",
    "                             recall_score)\n",
    "from train_with_mlflow_optuna import TrainMlflowOptuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9ba2f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def build_pipeline(model):\n",
    "    # Transformador para extraer la columna de texto\n",
    "    text_transformer = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(decode_error='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Transformador para columnas numéricas\n",
    "    numeric_transformer = 'passthrough'\n",
    "\n",
    "    # ColumnTransformer para aplicar transformaciones específicas\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', text_transformer, 'concatenada'),\n",
    "            ('num', numeric_transformer, ['sexo_codificado'])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Pipeline completo\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "00dfcc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "@task(name=\"etl_dataset\", retries=2, retry_delay_seconds=10)\n",
    "def task_generate_data(nregistros: int = 10000, db_server=os.getenv(\"DB_SERVER\"), \n",
    "                       db_name=os.getenv(\"DB_NAME\"),\n",
    "                       db_driver=os.getenv(\"DB_DRIVER\"),\n",
    "                       params = {\"medico\": \"PSICOLOGÍA\",\"fechaini\": \"20230101\",\"fechafin\": \"20250504\"}, \n",
    "                       sql_path = os.path.join(\"..\", \"..\", \"sql_queries\", \"queries.sql\")) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate synthetic user data for training.\n",
    "    \n",
    "    Args:\n",
    "        nregistros: Number of registros to generate\n",
    "        \n",
    "    Returns:\n",
    "        Generated dataframe\n",
    "    \"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(f\"Generating {nregistros} registros...\")\n",
    "    \n",
    "    # Generate data\n",
    "    load_dotenv()\n",
    "    db_server=os.getenv(\"DB_SERVER\")\n",
    "    db_name=os.getenv(\"DB_NAME\")\n",
    "    db_driver=os.getenv(\"DB_DRIVER\")\n",
    "    sqlconection = SQLConnection(sql_path=sql_path, db_server=db_server, db_name=db_name, db_driver=db_driver, params=params)\n",
    "    df_conexion = sqlconection.generate_dataframe(nregistros)\n",
    "    df_eda = EDAdataset(df_conexion)\n",
    "    df = df_eda.dataset_eda(df_conexion)\n",
    "        \n",
    "    # Create summary artifact\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Metric': ['Total Samples', 'Total Features', 'Missing Values'],\n",
    "        'Value': [\n",
    "            len(df),\n",
    "            len(df.columns),\n",
    "            df.isnull().sum().sum()\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    create_table_artifact(\n",
    "        key=\"etl-dataframe-summary\",\n",
    "        table=summary_df.to_dict(orient='records'),\n",
    "        description=f\"ETL Data Generation Summary - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Generated {len(df)} samples with {len(df.columns)} columns\")\n",
    "    return df\n",
    "\n",
    "\n",
    "@task(name=\"Feature_Engineering\", retries=2, retry_delay_seconds=10)\n",
    "def task_feature_engineering(df, stopwords={\n",
    "            \"medico\", \"paciente\", \"psicologo\", \"psicologa\",\n",
    "            \"psicologia\", \"psicoterapeuta\", \"psicoterapia\", \"refiere\"\n",
    "        }, columna_texto=\"concatenada\", columna_sexo=\"sexo\", columna_grupo=\"grupo\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply feature engineering to the dataset.\n",
    "    \n",
    "    Args:\n",
    "        df: Input dataframe\n",
    "        \n",
    "    Returns:\n",
    "        Feature-engineered dataframe\n",
    "    \"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"Starting feature engineering...\")\n",
    "    \n",
    "    initial_columns = len(df.columns)\n",
    "    preprocesador = PreprocesadorTexto(df, stopwords=stopwords)\n",
    "    df_engineered, _ = preprocesador.procesar(columna_texto=columna_texto, columna_sexo=columna_sexo, columna_grupo=columna_grupo)\n",
    "    \n",
    "    # Create feature engineering summary\n",
    "    feature_summary = pd.DataFrame({\n",
    "        'Metric': ['Initial Features', 'Final Features', 'Features Added', 'Dataset Size'],\n",
    "        'Value': [\n",
    "            initial_columns,\n",
    "            len(df_engineered.columns),\n",
    "            len(df_engineered.columns) - initial_columns,\n",
    "            f\"{len(df_engineered)} rows\",\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    create_table_artifact(\n",
    "        key=\"feature-engineering-summary\",\n",
    "        table=feature_summary.to_dict(orient='records'),\n",
    "        description=\"Feature Engineering Summary\"\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Feature engineering complete: {initial_columns} -> {len(df_engineered.columns)} features\")\n",
    "    return df_engineered\n",
    "\n",
    "@task(name=\"Train_Model_Optuna\", retries=1, retry_delay_seconds=30)\n",
    "def task_train_with_optuna(\n",
    "    df: pd.DataFrame,\n",
    "    model_type: str = \"LogisticRegression\",\n",
    "    n_trials: int = 20,\n",
    "    optimization_metric: str = \"accuracy\"\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Train model with Optuna hyperparameter optimization and MLflow tracking.\n",
    "    \n",
    "    Args:\n",
    "        df: Feature-engineered dataframe\n",
    "        model_type: Type of model to train ('LogisticRegression' or 'RandomForest')\n",
    "        n_trials: Number of Optuna trials\n",
    "        optimization_metric: Metric to optimize\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (best_pipeline, best_run_id, study, metrics_dict)\n",
    "    \"\"\"\n",
    "    def build_pipeline(model):\n",
    "        # Transformador para extraer la columna de texto\n",
    "        text_transformer = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(decode_error='ignore'))\n",
    "        ])\n",
    "\n",
    "        # Transformador para columnas numéricas\n",
    "        numeric_transformer = 'passthrough'\n",
    "\n",
    "        # ColumnTransformer para aplicar transformaciones específicas\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('text', text_transformer, 'concatenada'),\n",
    "                ('num', numeric_transformer, ['sexo_codificado'])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Pipeline completo\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "\n",
    "        return pipeline\n",
    "    logger = get_run_logger()\n",
    "    logger.info(f\"Starting Optuna optimization for {model_type} with {n_trials} trials...\")\n",
    "    \n",
    "    # Define Training Columns\n",
    "    training_columns = [\"concatenada\", \"sexo_codificado\"]\n",
    "    # Define target column\n",
    "    target_column = 'grupo_codificado'\n",
    "\n",
    "    # --- AJUSTE: Vectorizar columna de texto y concatenar con columnas numéricas ---\n",
    "    # vectorizer = TfidfVectorizer(decode_error='ignore')\n",
    "    # X = df[training_columns]\n",
    "    # X_text = vectorizer.fit_transform(X[\"concatenada\"].astype(str))\n",
    "    # numeric_cols = [col for col in training_columns if col != \"concatenada\"]\n",
    "    # X_numeric = X[numeric_cols].values\n",
    "    # X_final = hstack([X_text, csr_matrix(X_numeric)])\n",
    "    # y = df[target_column]\n",
    "    # --- FIN AJUSTE ---\n",
    "\n",
    "    # Define parameter distributions based on model type\n",
    "    if model_type == \"LogisticRegression\":\n",
    "        model_class = LogisticRegression\n",
    "        param_distributions = {\n",
    "            'C': ('float', 0.001, 100, True),\n",
    "            'penalty': ('categorical', ['l1', 'l2']),\n",
    "            'max_iter': ('int', 200, 2000),\n",
    "            'solver': ('categorical', ['liblinear', 'saga'])\n",
    "        }\n",
    "        fixed_params = {'random_state': 42}\n",
    "    elif model_type == \"RandomForest\":\n",
    "        model_class = RandomForestClassifier\n",
    "        param_distributions = {\n",
    "            'n_estimators': ('int', 50, 200),\n",
    "            'max_depth': ('int', 5, 30),\n",
    "            'min_samples_split': ('int', 2, 15),\n",
    "            'min_samples_leaf': ('int', 1, 10),\n",
    "            'max_features': ('categorical', ['sqrt', 'log2'])\n",
    "        }\n",
    "        fixed_params = {'random_state': 42, 'n_jobs': -1}\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    # Crear pipeline base\n",
    "    base_model = model_class()\n",
    "    pipeline = build_pipeline(base_model)\n",
    "    \n",
    "    # Set up MLflow\n",
    "    # mlflow.set_experiment(f\"prefect_{model_type.lower()}_training\")\n",
    "    model_name = type(pipeline.named_steps['classifier']).__name__\n",
    "    mlflow.set_experiment(f\"prefect_{model_name.lower()}_training\")\n",
    "\n",
    "    mlflow.sklearn.autolog()\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = TrainMlflowOptuna(\n",
    "        df=df,\n",
    "        target_column=target_column,\n",
    "        model_class=pipeline,\n",
    "        test_size=0.3,\n",
    "        n_trials=n_trials,\n",
    "        optimization_metric=optimization_metric,\n",
    "        param_distributions=param_distributions,\n",
    "        model_params=fixed_params\n",
    "    )\n",
    "    \n",
    "    # Run optimization\n",
    "    best_pipeline, best_run_id, study = trainer.train()\n",
    "\n",
    "    # --- AJUSTE: Validación usando datos vectorizados ---\n",
    "    # X_test = df[training_columns][:100]\n",
    "    # X_test_text = vectorizer.transform(X_test[\"concatenada\"].astype(str))\n",
    "    # X_test_numeric = X_test[numeric_cols].values\n",
    "    # X_test_final = hstack([X_test_text, csr_matrix(X_test_numeric)])\n",
    "    # y_test = df[target_column][:100]\n",
    "    # y_pred = best_pipeline.predict(X_test_final)\n",
    "    X_test = df[training_columns][:100]\n",
    "    y_test = df[target_column][:100]\n",
    "    y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "    metrics_dict = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "        'recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "        'f1': f1_score(y_test, y_pred, average='weighted')\n",
    "    }\n",
    "\n",
    "    logger.info(f\"Optimization complete! Best {optimization_metric}: {study.best_value:.4f}\")\n",
    "    logger.info(f\"Best parameters: {study.best_params}\")\n",
    "    logger.info(f\"MLflow Run ID: {best_run_id}\")\n",
    "\n",
    "    return best_pipeline, best_run_id, study, metrics_dict\n",
    "\n",
    "@task(name=\"Create_Model_Report\", retries=1)\n",
    "def task_create_model_report(\n",
    "    model_type: str,\n",
    "    best_run_id: str,\n",
    "    study,\n",
    "    metrics_dict: dict,\n",
    "    n_trials: int\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create comprehensive model training report as markdown artifact.\n",
    "    \n",
    "    Args:\n",
    "        model_type: Type of model trained\n",
    "        best_run_id: MLflow run ID\n",
    "        study: Optuna study object\n",
    "        metrics_dict: Dictionary of validation metrics\n",
    "        n_trials: Number of trials performed\n",
    "    \"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"Creating model training report...\")\n",
    "    \n",
    "    # Create markdown report\n",
    "    markdown_content = f\"\"\"\n",
    "# Model Training Report - {model_type}\n",
    "\n",
    "## Training Summary\n",
    "- **Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "- **Model Type**: {model_type}\n",
    "- **Number of Trials**: {n_trials}\n",
    "- **MLflow Run ID**: `{best_run_id}`\n",
    "\n",
    "## Optimization Results\n",
    "- **Best Score**: {study.best_value:.4f}\n",
    "- **Optimization Metric**: {study.trials[0].user_attrs.get('metric_name', 'accuracy') if study.trials else 'N/A'}\n",
    "- **Total Trials Completed**: {len([t for t in study.trials if t.state.name == 'COMPLETE'])}\n",
    "\n",
    "## Best Hyperparameters\n",
    "```python\n",
    "{json.dumps(study.best_params, indent=2)}\n",
    "```\n",
    "\n",
    "## Validation Metrics\n",
    "| Metric | Score |\n",
    "|--------|-------|\n",
    "| Accuracy | {metrics_dict['accuracy']:.4f} |\n",
    "| Precision | {metrics_dict['precision']:.4f} |\n",
    "| Recall | {metrics_dict['recall']:.4f} |\n",
    "| F1 Score | {metrics_dict['f1']:.4f} |\n",
    "\n",
    "## Top 5 Trials\n",
    "| Trial | Score | Parameters |\n",
    "|-------|-------|------------|\n",
    "\"\"\"\n",
    "    \n",
    "    # Add top 5 trials\n",
    "    sorted_trials = sorted(study.trials, key=lambda t: t.value if t.value else 0, reverse=True)[:5]\n",
    "    for trial in sorted_trials:\n",
    "        if trial.value:\n",
    "            params_str = ', '.join([f\"{k}={v}\" for k, v in list(trial.params.items())[:3]])\n",
    "            markdown_content += f\"| {trial.number} | {trial.value:.4f} | {params_str}... |\\n\"\n",
    "    \n",
    "    markdown_content += f\"\"\"\n",
    "\n",
    "## How to Use the Model\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "# Load the best model\n",
    "model = mlflow.sklearn.load_model(f\"runs:/{best_run_id}/model\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_new)\n",
    "```\n",
    "\n",
    "## Next Steps\n",
    "1. Review the model performance in MLflow UI\n",
    "2. Deploy the model if metrics meet requirements\n",
    "3. Monitor model performance in production\n",
    "\"\"\"\n",
    "    \n",
    "    create_markdown_artifact(\n",
    "        key=\"model-training-report\",\n",
    "        markdown=markdown_content,\n",
    "        description=f\"Complete Training Report for {model_type}\"\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Model training report created successfully\")\n",
    "\n",
    "\n",
    "@flow(name=\"Train_Model_With_Optuna\", log_prints=True)\n",
    "def train_model_flow(\n",
    "    nregistros: int = 10000,\n",
    "    model_type: str = \"LogisticRegression\",\n",
    "    n_trials: int = 20,\n",
    "    optimization_metric: str = \"accuracy\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Main Prefect flow for training models with Optuna optimization.\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Number of samples to generate\n",
    "        model_type: Type of model to train\n",
    "        n_trials: Number of Optuna trials\n",
    "        optimization_metric: Metric to optimize\n",
    "        \n",
    "    Returns:\n",
    "        Trained pipeline and MLflow run ID\n",
    "    \"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(f\"Starting training flow for {model_type}\")\n",
    "    \n",
    "    # Task 1: Generate data\n",
    "    df = task_generate_data(nregistros=nregistros)\n",
    "    \n",
    "    # Task 2: Feature engineering\n",
    "    df_engineered = task_feature_engineering(df)\n",
    "    df_engineered['concatenada'] = df_engineered['concatenada'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "    \n",
    "    # Task 3: Train with Optuna\n",
    "    best_pipeline, best_run_id, study, metrics_dict = task_train_with_optuna(\n",
    "        df_engineered,\n",
    "        model_type,\n",
    "        n_trials,\n",
    "        optimization_metric\n",
    "    )\n",
    "    \n",
    "    # Task 4: Create report\n",
    "    task_create_model_report(\n",
    "        model_type,\n",
    "        best_run_id,\n",
    "        study,\n",
    "        metrics_dict,\n",
    "        n_trials\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Training flow complete! Best model saved with run ID: {best_run_id}\")\n",
    "    \n",
    "    # Create final summary artifact\n",
    "    final_summary = pd.DataFrame({\n",
    "        'Metric': ['Model Type', 'Best Score', 'MLflow Run ID', 'Total Time'],\n",
    "        'Value': [\n",
    "            model_type,\n",
    "            f\"{study.best_value:.4f}\",\n",
    "            best_run_id,\n",
    "            f\"{sum((t.datetime_complete - t.datetime_start).total_seconds() for t in study.trials if t.datetime_complete):.2f}s\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    create_table_artifact(\n",
    "        key=\"training-flow-summary\",\n",
    "        table=final_summary.to_dict(orient='records'),\n",
    "        description=\"Final Training Flow Summary\"\n",
    "    )\n",
    "    \n",
    "    return best_pipeline, best_run_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9be6a09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:25:43.713 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'vague-pelican'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'vague-pelican'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Train_Model_With_Optuna'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:25:43.713 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'vague-pelican'\u001b[0m - Beginning flow run\u001b[35m 'vague-pelican'\u001b[0m for flow\u001b[1;35m 'Train_Model_With_Optuna'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:25:43.717 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'vague-pelican'</span> - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/runs/flow-run/a0c6d0d1-395a-4225-8a16-6a06eed18e32</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:25:43.717 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'vague-pelican'\u001b[0m - View at \u001b[94mhttp://127.0.0.1:4200/runs/flow-run/a0c6d0d1-395a-4225-8a16-6a06eed18e32\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:25:43.719 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'vague-pelican'</span> - Starting training flow for RandomForest\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:25:43.719 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'vague-pelican'\u001b[0m - Starting training flow for RandomForest\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:25:44.034 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'etl_dataset-c45' - Generating 5000 registros...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:25:44.034 | \u001b[36mINFO\u001b[0m    | Task run 'etl_dataset-c45' - Generating 5000 registros...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:26:00.442 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'etl_dataset-c45' - Generated 4931 samples with 7 columns\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:26:00.442 | \u001b[36mINFO\u001b[0m    | Task run 'etl_dataset-c45' - Generated 4931 samples with 7 columns\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:26:00.552 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'etl_dataset-c45' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:26:00.552 | \u001b[36mINFO\u001b[0m    | Task run 'etl_dataset-c45' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:26:00.953 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Feature_Engineering-810' - Starting feature engineering...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:26:00.953 | \u001b[36mINFO\u001b[0m    | Task run 'Feature_Engineering-810' - Starting feature engineering...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:30:38.090 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Feature_Engineering-810' - Feature engineering complete: 7 -&gt; 9 features\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:30:38.090 | \u001b[36mINFO\u001b[0m    | Task run 'Feature_Engineering-810' - Feature engineering complete: 7 -> 9 features\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:30:38.102 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Feature_Engineering-810' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:30:38.102 | \u001b[36mINFO\u001b[0m    | Task run 'Feature_Engineering-810' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:30:38.837 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Train_Model_Optuna-74c' - Starting Optuna optimization for RandomForest with 10 trials...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:30:38.837 | \u001b[36mINFO\u001b[0m    | Task run 'Train_Model_Optuna-74c' - Starting Optuna optimization for RandomForest with 10 trials...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:30:39.053 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Train_Model_Optuna-74c' - Task run failed with exception: AttributeError(\"'Pipeline' object has no attribute '__name__'\") - Retry 1/1 will start 30 second(s) from now\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:30:39.053 | \u001b[36mINFO\u001b[0m    | Task run 'Train_Model_Optuna-74c' - Task run failed with exception: AttributeError(\"'Pipeline' object has no attribute '__name__'\") - Retry 1/1 will start 30 second(s) from now\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:31:09.184 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Train_Model_Optuna-74c' - Starting Optuna optimization for RandomForest with 10 trials...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:31:09.184 | \u001b[36mINFO\u001b[0m    | Task run 'Train_Model_Optuna-74c' - Starting Optuna optimization for RandomForest with 10 trials...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:31:09.397 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'Train_Model_Optuna-74c' - Task run failed with exception: AttributeError(\"'Pipeline' object has no attribute '__name__'\") - Retries are exhausted\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 871, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 1512, in run_task_sync\n",
       "    engine.call_task_fn(txn)\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 888, in call_task_fn\n",
       "    result = call_with_parameters(self.task.fn, parameters)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^\n",
       "  File \"C:\\Users\\ISAIAS_QUINTERO\\AppData\\Local\\Temp\\ipykernel_26904\\1542256139.py\", line 200, in task_train_with_optuna\n",
       "    best_pipeline, best_run_id, study = trainer.train()\n",
       "                                        ^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\src\\training\\train_with_mlflow_optuna.py\", line 300, in train\n",
       "    return self.train_with_optuna()\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\src\\training\\train_with_mlflow_optuna.py\", line 195, in train_with_optuna\n",
       "    study_name=f\"optuna_{self.model_class.__name__}\"\n",
       "                         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "AttributeError: 'Pipeline' object has no attribute '__name__'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:31:09.397 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'Train_Model_Optuna-74c' - Task run failed with exception: AttributeError(\"'Pipeline' object has no attribute '__name__'\") - Retries are exhausted\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 871, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 1512, in run_task_sync\n",
       "    engine.call_task_fn(txn)\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 888, in call_task_fn\n",
       "    result = call_with_parameters(self.task.fn, parameters)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^\n",
       "  File \"C:\\Users\\ISAIAS_QUINTERO\\AppData\\Local\\Temp\\ipykernel_26904\\1542256139.py\", line 200, in task_train_with_optuna\n",
       "    best_pipeline, best_run_id, study = trainer.train()\n",
       "                                        ^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\src\\training\\train_with_mlflow_optuna.py\", line 300, in train\n",
       "    return self.train_with_optuna()\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\src\\training\\train_with_mlflow_optuna.py\", line 195, in train_with_optuna\n",
       "    study_name=f\"optuna_{self.model_class.__name__}\"\n",
       "                         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "AttributeError: 'Pipeline' object has no attribute '__name__'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:31:09.436 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'Train_Model_Optuna-74c' - Finished in state <span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span>(\"Task run encountered an exception AttributeError: 'Pipeline' object has no attribute '__name__'\")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:31:09.436 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'Train_Model_Optuna-74c' - Finished in state \u001b[38;5;160mFailed\u001b[0m(\"Task run encountered an exception AttributeError: 'Pipeline' object has no attribute '__name__'\")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:31:09.457 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'vague-pelican'</span> - Encountered exception during execution: AttributeError(\"'Pipeline' object has no attribute '__name__'\")\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py\", line 781, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py\", line 1395, in run_flow_sync\n",
       "    engine.call_flow_fn()\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py\", line 801, in call_flow_fn\n",
       "    result = call_with_parameters(self.flow.fn, self.parameters)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^\n",
       "  File \"C:\\Users\\ISAIAS_QUINTERO\\AppData\\Local\\Temp\\ipykernel_26904\\1542256139.py\", line 346, in train_model_flow\n",
       "    best_pipeline, best_run_id, study, metrics_dict = task_train_with_optuna(\n",
       "                                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\tasks.py\", line 1139, in __call__\n",
       "    return run_task(\n",
       "           ^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 1739, in run_task\n",
       "    return run_task_sync(**kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 1514, in run_task_sync\n",
       "    return engine.state if return_type == \"state\" else engine.result()\n",
       "                                                       ^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 493, in result\n",
       "    raise self._raised\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 871, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 1512, in run_task_sync\n",
       "    engine.call_task_fn(txn)\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 888, in call_task_fn\n",
       "    result = call_with_parameters(self.task.fn, parameters)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^\n",
       "  File \"C:\\Users\\ISAIAS_QUINTERO\\AppData\\Local\\Temp\\ipykernel_26904\\1542256139.py\", line 200, in task_train_with_optuna\n",
       "    best_pipeline, best_run_id, study = trainer.train()\n",
       "                                        ^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\src\\training\\train_with_mlflow_optuna.py\", line 300, in train\n",
       "    return self.train_with_optuna()\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\src\\training\\train_with_mlflow_optuna.py\", line 195, in train_with_optuna\n",
       "    study_name=f\"optuna_{self.model_class.__name__}\"\n",
       "                         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "AttributeError: 'Pipeline' object has no attribute '__name__'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:31:09.457 | \u001b[38;5;160mERROR\u001b[0m   | Flow run\u001b[35m 'vague-pelican'\u001b[0m - Encountered exception during execution: AttributeError(\"'Pipeline' object has no attribute '__name__'\")\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py\", line 781, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py\", line 1395, in run_flow_sync\n",
       "    engine.call_flow_fn()\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py\", line 801, in call_flow_fn\n",
       "    result = call_with_parameters(self.flow.fn, self.parameters)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^\n",
       "  File \"C:\\Users\\ISAIAS_QUINTERO\\AppData\\Local\\Temp\\ipykernel_26904\\1542256139.py\", line 346, in train_model_flow\n",
       "    best_pipeline, best_run_id, study, metrics_dict = task_train_with_optuna(\n",
       "                                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\tasks.py\", line 1139, in __call__\n",
       "    return run_task(\n",
       "           ^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 1739, in run_task\n",
       "    return run_task_sync(**kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 1514, in run_task_sync\n",
       "    return engine.state if return_type == \"state\" else engine.result()\n",
       "                                                       ^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 493, in result\n",
       "    raise self._raised\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 871, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 1512, in run_task_sync\n",
       "    engine.call_task_fn(txn)\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 888, in call_task_fn\n",
       "    result = call_with_parameters(self.task.fn, parameters)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^\n",
       "  File \"C:\\Users\\ISAIAS_QUINTERO\\AppData\\Local\\Temp\\ipykernel_26904\\1542256139.py\", line 200, in task_train_with_optuna\n",
       "    best_pipeline, best_run_id, study = trainer.train()\n",
       "                                        ^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\src\\training\\train_with_mlflow_optuna.py\", line 300, in train\n",
       "    return self.train_with_optuna()\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\src\\training\\train_with_mlflow_optuna.py\", line 195, in train_with_optuna\n",
       "    study_name=f\"optuna_{self.model_class.__name__}\"\n",
       "                         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "AttributeError: 'Pipeline' object has no attribute '__name__'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:31:09.565 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'vague-pelican'</span> - Finished in state <span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span>(\"Flow run encountered an exception: AttributeError: 'Pipeline' object has no attribute '__name__'\")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:31:09.565 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'vague-pelican'\u001b[0m - Finished in state \u001b[38;5;160mFailed\u001b[0m(\"Flow run encountered an exception: AttributeError: 'Pipeline' object has no attribute '__name__'\")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute '__name__'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Example 1: Train a single model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m pipeline, run_id = \u001b[43mtrain_model_flow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnregistros\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRandomForest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimization_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Example 2: Compare multiple models\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# results = compare_models_flow(n_samples=5000, n_trials=10)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flows.py:1702\u001b[39m, in \u001b[36mFlow.__call__\u001b[39m\u001b[34m(self, return_state, wait_for, *args, **kwargs)\u001b[39m\n\u001b[32m   1698\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m track_viz_task(\u001b[38;5;28mself\u001b[39m.isasync, \u001b[38;5;28mself\u001b[39m.name, parameters)\n\u001b[32m   1700\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mprefect\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflow_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_flow\n\u001b[32m-> \u001b[39m\u001b[32m1702\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_flow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1704\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1705\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwait_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1707\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py:1552\u001b[39m, in \u001b[36mrun_flow\u001b[39m\u001b[34m(flow, flow_run, parameters, wait_for, return_type, error_logger, context)\u001b[39m\n\u001b[32m   1550\u001b[39m         ret_val = run_flow_async(**kwargs)\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1552\u001b[39m         ret_val = \u001b[43mrun_flow_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (Abort, Pause):\n\u001b[32m   1554\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py:1397\u001b[39m, in \u001b[36mrun_flow_sync\u001b[39m\u001b[34m(flow, flow_run, parameters, wait_for, return_type, context)\u001b[39m\n\u001b[32m   1394\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m engine.run_context():\n\u001b[32m   1395\u001b[39m             engine.call_flow_fn()\n\u001b[32m-> \u001b[39m\u001b[32m1397\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m engine.state \u001b[38;5;28;01mif\u001b[39;00m return_type == \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py:361\u001b[39m, in \u001b[36mFlowRunEngine.result\u001b[39m\u001b[34m(self, raise_on_failure)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m NotSet:\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_failure:\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised\n\u001b[32m    364\u001b[39m \u001b[38;5;66;03m# This is a fall through case which leans on the existing state result mechanics to get the\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[38;5;66;03m# return value. This is necessary because we currently will return a State object if the\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[38;5;66;03m# the State was Prefect-created.\u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[38;5;66;03m# TODO: Remove the need to get the result from a State except in cases where the return value\u001b[39;00m\n\u001b[32m    368\u001b[39m \u001b[38;5;66;03m# is a State object.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py:781\u001b[39m, in \u001b[36mFlowRunEngine.run_context\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m timeout_context(\n\u001b[32m    775\u001b[39m         seconds=\u001b[38;5;28mself\u001b[39m.flow.timeout_seconds,\n\u001b[32m    776\u001b[39m         timeout_exc_type=FlowRunTimeoutError,\n\u001b[32m    777\u001b[39m     ):\n\u001b[32m    778\u001b[39m         \u001b[38;5;28mself\u001b[39m.logger.debug(\n\u001b[32m    779\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecuting flow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.flow.name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m for flow run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.flow_run.name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    780\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m781\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m    782\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    783\u001b[39m     \u001b[38;5;28mself\u001b[39m.handle_timeout(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py:1395\u001b[39m, in \u001b[36mrun_flow_sync\u001b[39m\u001b[34m(flow, flow_run, parameters, wait_for, return_type, context)\u001b[39m\n\u001b[32m   1393\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m engine.is_running():\n\u001b[32m   1394\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m engine.run_context():\n\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m             \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_flow_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m engine.state \u001b[38;5;28;01mif\u001b[39;00m return_type == \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m engine.result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py:801\u001b[39m, in \u001b[36mFlowRunEngine.call_flow_fn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    799\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_flow_fn()\n\u001b[32m    800\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m801\u001b[39m     result = \u001b[43mcall_with_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m     \u001b[38;5;28mself\u001b[39m.handle_success(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\utilities\\callables.py:210\u001b[39m, in \u001b[36mcall_with_parameters\u001b[39m\u001b[34m(fn, parameters)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03mCall a function with parameters extracted with `get_call_parameters`\u001b[39;00m\n\u001b[32m    204\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    207\u001b[39m \u001b[33;03mthe args/kwargs using `parameters_to_positional_and_keyword` directly\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    209\u001b[39m args, kwargs = parameters_to_args_kwargs(fn, parameters)\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 346\u001b[39m, in \u001b[36mtrain_model_flow\u001b[39m\u001b[34m(nregistros, model_type, n_trials, optimization_metric)\u001b[39m\n\u001b[32m    343\u001b[39m df_engineered[\u001b[33m'\u001b[39m\u001b[33mconcatenada\u001b[39m\u001b[33m'\u001b[39m] = df_engineered[\u001b[33m'\u001b[39m\u001b[33mconcatenada\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x)\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# Task 3: Train with Optuna\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m best_pipeline, best_run_id, study, metrics_dict = \u001b[43mtask_train_with_optuna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_engineered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimization_metric\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# Task 4: Create report\u001b[39;00m\n\u001b[32m    354\u001b[39m task_create_model_report(\n\u001b[32m    355\u001b[39m     model_type,\n\u001b[32m    356\u001b[39m     best_run_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m    359\u001b[39m     n_trials\n\u001b[32m    360\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\tasks.py:1139\u001b[39m, in \u001b[36mTask.__call__\u001b[39m\u001b[34m(self, return_state, wait_for, *args, **kwargs)\u001b[39m\n\u001b[32m   1133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m track_viz_task(\n\u001b[32m   1134\u001b[39m         \u001b[38;5;28mself\u001b[39m.isasync, \u001b[38;5;28mself\u001b[39m.name, parameters, \u001b[38;5;28mself\u001b[39m.viz_return_value\n\u001b[32m   1135\u001b[39m     )\n\u001b[32m   1137\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mprefect\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtask_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_task\n\u001b[32m-> \u001b[39m\u001b[32m1139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwait_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py:1739\u001b[39m, in \u001b[36mrun_task\u001b[39m\u001b[34m(task, task_run_id, task_run, parameters, wait_for, return_type, dependencies, context)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m run_task_async(**kwargs)\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_task_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py:1514\u001b[39m, in \u001b[36mrun_task_sync\u001b[39m\u001b[34m(task, task_run_id, task_run, parameters, wait_for, return_type, dependencies, context)\u001b[39m\n\u001b[32m   1507\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[32m   1508\u001b[39m             engine.asset_context(),\n\u001b[32m   1509\u001b[39m             engine.run_context(),\n\u001b[32m   1510\u001b[39m             engine.transaction_context() \u001b[38;5;28;01mas\u001b[39;00m txn,\n\u001b[32m   1511\u001b[39m         ):\n\u001b[32m   1512\u001b[39m             engine.call_task_fn(txn)\n\u001b[32m-> \u001b[39m\u001b[32m1514\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m engine.state \u001b[38;5;28;01mif\u001b[39;00m return_type == \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py:493\u001b[39m, in \u001b[36mSyncTaskRunEngine.result\u001b[39m\u001b[34m(self, raise_on_failure)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m NotSet:\n\u001b[32m    491\u001b[39m     \u001b[38;5;66;03m# if the task raised an exception, raise it\u001b[39;00m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_failure:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised\n\u001b[32m    495\u001b[39m     \u001b[38;5;66;03m# otherwise, return the exception\u001b[39;00m\n\u001b[32m    496\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py:871\u001b[39m, in \u001b[36mSyncTaskRunEngine.run_context\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    868\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_cancelled():\n\u001b[32m    869\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m CancelledError(\u001b[33m\"\u001b[39m\u001b[33mTask run cancelled by the task runner\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    873\u001b[39m     \u001b[38;5;28mself\u001b[39m.handle_timeout(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py:1512\u001b[39m, in \u001b[36mrun_task_sync\u001b[39m\u001b[34m(task, task_run_id, task_run, parameters, wait_for, return_type, dependencies, context)\u001b[39m\n\u001b[32m   1506\u001b[39m         run_coro_as_sync(engine.wait_until_ready())\n\u001b[32m   1507\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[32m   1508\u001b[39m             engine.asset_context(),\n\u001b[32m   1509\u001b[39m             engine.run_context(),\n\u001b[32m   1510\u001b[39m             engine.transaction_context() \u001b[38;5;28;01mas\u001b[39;00m txn,\n\u001b[32m   1511\u001b[39m         ):\n\u001b[32m-> \u001b[39m\u001b[32m1512\u001b[39m             \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_task_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtxn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1514\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m engine.state \u001b[38;5;28;01mif\u001b[39;00m return_type == \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m engine.result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py:888\u001b[39m, in \u001b[36mSyncTaskRunEngine.call_task_fn\u001b[39m\u001b[34m(self, transaction)\u001b[39m\n\u001b[32m    886\u001b[39m     result = transaction.read()\n\u001b[32m    887\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m888\u001b[39m     result = \u001b[43mcall_with_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;28mself\u001b[39m.handle_success(result, transaction=transaction)\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\utilities\\callables.py:210\u001b[39m, in \u001b[36mcall_with_parameters\u001b[39m\u001b[34m(fn, parameters)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03mCall a function with parameters extracted with `get_call_parameters`\u001b[39;00m\n\u001b[32m    204\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    207\u001b[39m \u001b[33;03mthe args/kwargs using `parameters_to_positional_and_keyword` directly\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    209\u001b[39m args, kwargs = parameters_to_args_kwargs(fn, parameters)\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 200\u001b[39m, in \u001b[36mtask_train_with_optuna\u001b[39m\u001b[34m(df, model_type, n_trials, optimization_metric)\u001b[39m\n\u001b[32m    188\u001b[39m trainer = TrainMlflowOptuna(\n\u001b[32m    189\u001b[39m     df=df,\n\u001b[32m    190\u001b[39m     target_column=target_column,\n\u001b[32m   (...)\u001b[39m\u001b[32m    196\u001b[39m     model_params=fixed_params\n\u001b[32m    197\u001b[39m )\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# Run optimization\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m best_pipeline, best_run_id, study = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# --- AJUSTE: Validación usando datos vectorizados ---\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;66;03m# X_test = df[training_columns][:100]\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[38;5;66;03m# X_test_text = vectorizer.transform(X_test[\"concatenada\"].astype(str))\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# y_test = df[target_column][:100]\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# y_pred = best_pipeline.predict(X_test_final)\u001b[39;00m\n\u001b[32m    209\u001b[39m X_test = df[training_columns][:\u001b[32m100\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\src\\training\\train_with_mlflow_optuna.py:300\u001b[39m, in \u001b[36mTrainMlflowOptuna.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    299\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Alias for train_with_optuna to maintain compatibility.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_with_optuna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\src\\training\\train_with_mlflow_optuna.py:195\u001b[39m, in \u001b[36mTrainMlflowOptuna.train_with_optuna\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    190\u001b[39m X_train, X_test, y_train, y_test = \u001b[38;5;28mself\u001b[39m.train_test_split()\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# Create Optuna study\u001b[39;00m\n\u001b[32m    193\u001b[39m study = optuna.create_study(\n\u001b[32m    194\u001b[39m     direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     study_name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33moptuna_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    196\u001b[39m )\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# Create objective function\u001b[39;00m\n\u001b[32m    199\u001b[39m objective = \u001b[38;5;28mself\u001b[39m.create_objective(X_train, X_test, y_train, y_test)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Pipeline' object has no attribute '__name__'"
     ]
    }
   ],
   "source": [
    "# Example 1: Train a single model\n",
    "pipeline, run_id = train_model_flow(\n",
    "    nregistros=5000,\n",
    "    model_type=\"RandomForest\",\n",
    "    n_trials=10,\n",
    "    optimization_metric=\"accuracy\"\n",
    "    )\n",
    "\n",
    "# Example 2: Compare multiple models\n",
    "# results = compare_models_flow(n_samples=5000, n_trials=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proyecto_Final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
