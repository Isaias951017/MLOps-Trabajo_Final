{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09085b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from etl import EDAdataset\n",
    "from utils.conexion import SQLConnection\n",
    "from feature_engineer import PreprocesadorTexto\n",
    "from prefect import flow, get_run_logger, task\n",
    "from prefect.artifacts import create_markdown_artifact, create_table_artifact\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score,\n",
    "                             recall_score)\n",
    "from train_with_mlflow_optuna import TrainMlflowOptuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dfcc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:29:42.742 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect - Starting temporary server on <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:8174</span>\n",
       "See <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://docs.prefect.io/v3/concepts/server#how-to-guides</span> for more information on running a dedicated Prefect server.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:29:42.742 | \u001b[36mINFO\u001b[0m    | prefect - Starting temporary server on \u001b[94mhttp://127.0.0.1:8174\u001b[0m\n",
       "See \u001b[94mhttps://docs.prefect.io/v3/concepts/server#how-to-guides\u001b[0m for more information on running a dedicated Prefect server.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:29:59.025 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'keen-yak'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'keen-yak'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Train_Model_With_Optuna'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:29:59.025 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'keen-yak'\u001b[0m - Beginning flow run\u001b[35m 'keen-yak'\u001b[0m for flow\u001b[1;35m 'Train_Model_With_Optuna'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:29:59.027 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'keen-yak'</span> - Starting training flow for LogisticRegression\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:29:59.027 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'keen-yak'\u001b[0m - Starting training flow for LogisticRegression\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:29:59.393 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'etl_dataset-bef' - Generating 5000 registros...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:29:59.393 | \u001b[36mINFO\u001b[0m    | Task run 'etl_dataset-bef' - Generating 5000 registros...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:29:59.394 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'etl_dataset-bef' - Task run failed with exception: FileNotFoundError(2, 'No such file or directory') - Retry 1/2 will start 10 second(s) from now\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:29:59.394 | \u001b[36mINFO\u001b[0m    | Task run 'etl_dataset-bef' - Task run failed with exception: FileNotFoundError(2, 'No such file or directory') - Retry 1/2 will start 10 second(s) from now\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:30:09.410 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'etl_dataset-bef' - Generating 5000 registros...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:30:09.410 | \u001b[36mINFO\u001b[0m    | Task run 'etl_dataset-bef' - Generating 5000 registros...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:30:09.410 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'etl_dataset-bef' - Task run failed with exception: FileNotFoundError(2, 'No such file or directory') - Retry 2/2 will start 10 second(s) from now\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:30:09.410 | \u001b[36mINFO\u001b[0m    | Task run 'etl_dataset-bef' - Task run failed with exception: FileNotFoundError(2, 'No such file or directory') - Retry 2/2 will start 10 second(s) from now\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:30:19.431 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'etl_dataset-bef' - Generating 5000 registros...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:30:19.431 | \u001b[36mINFO\u001b[0m    | Task run 'etl_dataset-bef' - Generating 5000 registros...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:30:19.440 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'etl_dataset-bef' - Task run failed with exception: FileNotFoundError(2, 'No such file or directory') - Retries are exhausted\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 871, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 1512, in run_task_sync\n",
       "    engine.call_task_fn(txn)\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 888, in call_task_fn\n",
       "    result = call_with_parameters(self.task.fn, parameters)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^\n",
       "  File \"C:\\Users\\ISAIAS_QUINTERO\\AppData\\Local\\Temp\\ipykernel_30396\\2363855677.py\", line 18, in task_generate_data\n",
       "    df = sqlconection.generate_dataframe(n_registros)\n",
       "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\src\\utils\\conexion.py\", line 27, in generate_dataframe\n",
       "    with open(self.sql_path, \"r\", encoding=\"utf-8\") as file:\n",
       "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "FileNotFoundError: [Errno 2] No such file or directory: '..\\\\sql_queries\\\\queries.sql'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:30:19.440 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'etl_dataset-bef' - Task run failed with exception: FileNotFoundError(2, 'No such file or directory') - Retries are exhausted\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 871, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 1512, in run_task_sync\n",
       "    engine.call_task_fn(txn)\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 888, in call_task_fn\n",
       "    result = call_with_parameters(self.task.fn, parameters)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^\n",
       "  File \"C:\\Users\\ISAIAS_QUINTERO\\AppData\\Local\\Temp\\ipykernel_30396\\2363855677.py\", line 18, in task_generate_data\n",
       "    df = sqlconection.generate_dataframe(n_registros)\n",
       "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\src\\utils\\conexion.py\", line 27, in generate_dataframe\n",
       "    with open(self.sql_path, \"r\", encoding=\"utf-8\") as file:\n",
       "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "FileNotFoundError: [Errno 2] No such file or directory: '..\\\\sql_queries\\\\queries.sql'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:30:19.476 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'etl_dataset-bef' - Finished in state <span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span>(\"Task run encountered an exception FileNotFoundError: [Errno 2] No such file or directory: '..\\\\\\\\sql_queries\\\\\\\\queries.sql'\")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:30:19.476 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'etl_dataset-bef' - Finished in state \u001b[38;5;160mFailed\u001b[0m(\"Task run encountered an exception FileNotFoundError: [Errno 2] No such file or directory: '..\\\\\\\\sql_queries\\\\\\\\queries.sql'\")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:30:19.483 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'keen-yak'</span> - Encountered exception during execution: FileNotFoundError(2, 'No such file or directory')\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py\", line 781, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py\", line 1395, in run_flow_sync\n",
       "    engine.call_flow_fn()\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py\", line 801, in call_flow_fn\n",
       "    result = call_with_parameters(self.flow.fn, self.parameters)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^\n",
       "  File \"C:\\Users\\ISAIAS_QUINTERO\\AppData\\Local\\Temp\\ipykernel_30396\\2363855677.py\", line 317, in train_model_flow\n",
       "    df = task_generate_data(n_registros=n_registros)\n",
       "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\tasks.py\", line 1139, in __call__\n",
       "    return run_task(\n",
       "           ^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 1739, in run_task\n",
       "    return run_task_sync(**kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 1514, in run_task_sync\n",
       "    return engine.state if return_type == \"state\" else engine.result()\n",
       "                                                       ^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 493, in result\n",
       "    raise self._raised\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 871, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 1512, in run_task_sync\n",
       "    engine.call_task_fn(txn)\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 888, in call_task_fn\n",
       "    result = call_with_parameters(self.task.fn, parameters)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^\n",
       "  File \"C:\\Users\\ISAIAS_QUINTERO\\AppData\\Local\\Temp\\ipykernel_30396\\2363855677.py\", line 18, in task_generate_data\n",
       "    df = sqlconection.generate_dataframe(n_registros)\n",
       "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\src\\utils\\conexion.py\", line 27, in generate_dataframe\n",
       "    with open(self.sql_path, \"r\", encoding=\"utf-8\") as file:\n",
       "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "FileNotFoundError: [Errno 2] No such file or directory: '..\\\\sql_queries\\\\queries.sql'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:30:19.483 | \u001b[38;5;160mERROR\u001b[0m   | Flow run\u001b[35m 'keen-yak'\u001b[0m - Encountered exception during execution: FileNotFoundError(2, 'No such file or directory')\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py\", line 781, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py\", line 1395, in run_flow_sync\n",
       "    engine.call_flow_fn()\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py\", line 801, in call_flow_fn\n",
       "    result = call_with_parameters(self.flow.fn, self.parameters)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^\n",
       "  File \"C:\\Users\\ISAIAS_QUINTERO\\AppData\\Local\\Temp\\ipykernel_30396\\2363855677.py\", line 317, in train_model_flow\n",
       "    df = task_generate_data(n_registros=n_registros)\n",
       "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\tasks.py\", line 1139, in __call__\n",
       "    return run_task(\n",
       "           ^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 1739, in run_task\n",
       "    return run_task_sync(**kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 1514, in run_task_sync\n",
       "    return engine.state if return_type == \"state\" else engine.result()\n",
       "                                                       ^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 493, in result\n",
       "    raise self._raised\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 871, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 1512, in run_task_sync\n",
       "    engine.call_task_fn(txn)\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py\", line 888, in call_task_fn\n",
       "    result = call_with_parameters(self.task.fn, parameters)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^\n",
       "  File \"C:\\Users\\ISAIAS_QUINTERO\\AppData\\Local\\Temp\\ipykernel_30396\\2363855677.py\", line 18, in task_generate_data\n",
       "    df = sqlconection.generate_dataframe(n_registros)\n",
       "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"c:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\src\\utils\\conexion.py\", line 27, in generate_dataframe\n",
       "    with open(self.sql_path, \"r\", encoding=\"utf-8\") as file:\n",
       "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "FileNotFoundError: [Errno 2] No such file or directory: '..\\\\sql_queries\\\\queries.sql'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:30:19.530 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'keen-yak'</span> - Finished in state <span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span>(\"Flow run encountered an exception: FileNotFoundError: [Errno 2] No such file or directory: '..\\\\\\\\sql_queries\\\\\\\\queries.sql'\")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:30:19.530 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'keen-yak'\u001b[0m - Finished in state \u001b[38;5;160mFailed\u001b[0m(\"Flow run encountered an exception: FileNotFoundError: [Errno 2] No such file or directory: '..\\\\\\\\sql_queries\\\\\\\\queries.sql'\")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\sql_queries\\\\queries.sql'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 434\u001b[39m\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    433\u001b[39m     \u001b[38;5;66;03m# Example 1: Train a single model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m     pipeline, run_id = \u001b[43mtrain_model_flow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_registros\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLogisticRegression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimization_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    439\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m     \u001b[38;5;66;03m# Example 2: Compare multiple models\u001b[39;00m\n\u001b[32m    442\u001b[39m     \u001b[38;5;66;03m# results = compare_models_flow(n_samples=5000, n_trials=10)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flows.py:1702\u001b[39m, in \u001b[36mFlow.__call__\u001b[39m\u001b[34m(self, return_state, wait_for, *args, **kwargs)\u001b[39m\n\u001b[32m   1698\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m track_viz_task(\u001b[38;5;28mself\u001b[39m.isasync, \u001b[38;5;28mself\u001b[39m.name, parameters)\n\u001b[32m   1700\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mprefect\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflow_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_flow\n\u001b[32m-> \u001b[39m\u001b[32m1702\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_flow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1704\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1705\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwait_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1707\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py:1552\u001b[39m, in \u001b[36mrun_flow\u001b[39m\u001b[34m(flow, flow_run, parameters, wait_for, return_type, error_logger, context)\u001b[39m\n\u001b[32m   1550\u001b[39m         ret_val = run_flow_async(**kwargs)\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1552\u001b[39m         ret_val = \u001b[43mrun_flow_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (Abort, Pause):\n\u001b[32m   1554\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py:1397\u001b[39m, in \u001b[36mrun_flow_sync\u001b[39m\u001b[34m(flow, flow_run, parameters, wait_for, return_type, context)\u001b[39m\n\u001b[32m   1394\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m engine.run_context():\n\u001b[32m   1395\u001b[39m             engine.call_flow_fn()\n\u001b[32m-> \u001b[39m\u001b[32m1397\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m engine.state \u001b[38;5;28;01mif\u001b[39;00m return_type == \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py:361\u001b[39m, in \u001b[36mFlowRunEngine.result\u001b[39m\u001b[34m(self, raise_on_failure)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m NotSet:\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_failure:\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised\n\u001b[32m    364\u001b[39m \u001b[38;5;66;03m# This is a fall through case which leans on the existing state result mechanics to get the\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[38;5;66;03m# return value. This is necessary because we currently will return a State object if the\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[38;5;66;03m# the State was Prefect-created.\u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[38;5;66;03m# TODO: Remove the need to get the result from a State except in cases where the return value\u001b[39;00m\n\u001b[32m    368\u001b[39m \u001b[38;5;66;03m# is a State object.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py:781\u001b[39m, in \u001b[36mFlowRunEngine.run_context\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m timeout_context(\n\u001b[32m    775\u001b[39m         seconds=\u001b[38;5;28mself\u001b[39m.flow.timeout_seconds,\n\u001b[32m    776\u001b[39m         timeout_exc_type=FlowRunTimeoutError,\n\u001b[32m    777\u001b[39m     ):\n\u001b[32m    778\u001b[39m         \u001b[38;5;28mself\u001b[39m.logger.debug(\n\u001b[32m    779\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecuting flow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.flow.name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m for flow run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.flow_run.name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    780\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m781\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m    782\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    783\u001b[39m     \u001b[38;5;28mself\u001b[39m.handle_timeout(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py:1395\u001b[39m, in \u001b[36mrun_flow_sync\u001b[39m\u001b[34m(flow, flow_run, parameters, wait_for, return_type, context)\u001b[39m\n\u001b[32m   1393\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m engine.is_running():\n\u001b[32m   1394\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m engine.run_context():\n\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m             \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_flow_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m engine.state \u001b[38;5;28;01mif\u001b[39;00m return_type == \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m engine.result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\flow_engine.py:801\u001b[39m, in \u001b[36mFlowRunEngine.call_flow_fn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    799\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_flow_fn()\n\u001b[32m    800\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m801\u001b[39m     result = \u001b[43mcall_with_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m     \u001b[38;5;28mself\u001b[39m.handle_success(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\utilities\\callables.py:210\u001b[39m, in \u001b[36mcall_with_parameters\u001b[39m\u001b[34m(fn, parameters)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03mCall a function with parameters extracted with `get_call_parameters`\u001b[39;00m\n\u001b[32m    204\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    207\u001b[39m \u001b[33;03mthe args/kwargs using `parameters_to_positional_and_keyword` directly\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    209\u001b[39m args, kwargs = parameters_to_args_kwargs(fn, parameters)\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 317\u001b[39m, in \u001b[36mtrain_model_flow\u001b[39m\u001b[34m(n_registros, model_type, n_trials, optimization_metric)\u001b[39m\n\u001b[32m    314\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting training flow for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# Task 1: Generate data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m df = \u001b[43mtask_generate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_registros\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_registros\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[38;5;66;03m# Task 2: Feature engineering\u001b[39;00m\n\u001b[32m    320\u001b[39m df_engineered = task_feature_engineering(df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\tasks.py:1139\u001b[39m, in \u001b[36mTask.__call__\u001b[39m\u001b[34m(self, return_state, wait_for, *args, **kwargs)\u001b[39m\n\u001b[32m   1133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m track_viz_task(\n\u001b[32m   1134\u001b[39m         \u001b[38;5;28mself\u001b[39m.isasync, \u001b[38;5;28mself\u001b[39m.name, parameters, \u001b[38;5;28mself\u001b[39m.viz_return_value\n\u001b[32m   1135\u001b[39m     )\n\u001b[32m   1137\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mprefect\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtask_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_task\n\u001b[32m-> \u001b[39m\u001b[32m1139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwait_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py:1739\u001b[39m, in \u001b[36mrun_task\u001b[39m\u001b[34m(task, task_run_id, task_run, parameters, wait_for, return_type, dependencies, context)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m run_task_async(**kwargs)\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_task_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py:1514\u001b[39m, in \u001b[36mrun_task_sync\u001b[39m\u001b[34m(task, task_run_id, task_run, parameters, wait_for, return_type, dependencies, context)\u001b[39m\n\u001b[32m   1507\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[32m   1508\u001b[39m             engine.asset_context(),\n\u001b[32m   1509\u001b[39m             engine.run_context(),\n\u001b[32m   1510\u001b[39m             engine.transaction_context() \u001b[38;5;28;01mas\u001b[39;00m txn,\n\u001b[32m   1511\u001b[39m         ):\n\u001b[32m   1512\u001b[39m             engine.call_task_fn(txn)\n\u001b[32m-> \u001b[39m\u001b[32m1514\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m engine.state \u001b[38;5;28;01mif\u001b[39;00m return_type == \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py:493\u001b[39m, in \u001b[36mSyncTaskRunEngine.result\u001b[39m\u001b[34m(self, raise_on_failure)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m NotSet:\n\u001b[32m    491\u001b[39m     \u001b[38;5;66;03m# if the task raised an exception, raise it\u001b[39;00m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_failure:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised\n\u001b[32m    495\u001b[39m     \u001b[38;5;66;03m# otherwise, return the exception\u001b[39;00m\n\u001b[32m    496\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py:871\u001b[39m, in \u001b[36mSyncTaskRunEngine.run_context\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    868\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_cancelled():\n\u001b[32m    869\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m CancelledError(\u001b[33m\"\u001b[39m\u001b[33mTask run cancelled by the task runner\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    873\u001b[39m     \u001b[38;5;28mself\u001b[39m.handle_timeout(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py:1512\u001b[39m, in \u001b[36mrun_task_sync\u001b[39m\u001b[34m(task, task_run_id, task_run, parameters, wait_for, return_type, dependencies, context)\u001b[39m\n\u001b[32m   1506\u001b[39m         run_coro_as_sync(engine.wait_until_ready())\n\u001b[32m   1507\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[32m   1508\u001b[39m             engine.asset_context(),\n\u001b[32m   1509\u001b[39m             engine.run_context(),\n\u001b[32m   1510\u001b[39m             engine.transaction_context() \u001b[38;5;28;01mas\u001b[39;00m txn,\n\u001b[32m   1511\u001b[39m         ):\n\u001b[32m-> \u001b[39m\u001b[32m1512\u001b[39m             \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_task_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtxn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1514\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m engine.state \u001b[38;5;28;01mif\u001b[39;00m return_type == \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m engine.result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\task_engine.py:888\u001b[39m, in \u001b[36mSyncTaskRunEngine.call_task_fn\u001b[39m\u001b[34m(self, transaction)\u001b[39m\n\u001b[32m    886\u001b[39m     result = transaction.read()\n\u001b[32m    887\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m888\u001b[39m     result = \u001b[43mcall_with_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;28mself\u001b[39m.handle_success(result, transaction=transaction)\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\.venv\\Lib\\site-packages\\prefect\\utilities\\callables.py:210\u001b[39m, in \u001b[36mcall_with_parameters\u001b[39m\u001b[34m(fn, parameters)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03mCall a function with parameters extracted with `get_call_parameters`\u001b[39;00m\n\u001b[32m    204\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    207\u001b[39m \u001b[33;03mthe args/kwargs using `parameters_to_positional_and_keyword` directly\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    209\u001b[39m args, kwargs = parameters_to_args_kwargs(fn, parameters)\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mtask_generate_data\u001b[39m\u001b[34m(n_registros, params, sql_path)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Generate data\u001b[39;00m\n\u001b[32m     17\u001b[39m sqlconection = SQLConnection(sql_path=sql_path, params=params)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m df = \u001b[43msqlconection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_registros\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m df = EDAdataset(df)\n\u001b[32m     20\u001b[39m df = df.dataset_eda(df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ISAIAS_QUINTERO\\Desktop\\Universiad\\MLOps\\Proyecto_Final\\src\\utils\\conexion.py:27\u001b[39m, in \u001b[36mSQLConnection.generate_dataframe\u001b[39m\u001b[34m(self, nregistros)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_dataframe\u001b[39m(\u001b[38;5;28mself\u001b[39m, nregistros=\u001b[32m10000\u001b[39m):\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mself\u001b[39m.nregistros = nregistros\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msql_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file: \n\u001b[32m     28\u001b[39m         query = file.read()\n\u001b[32m     30\u001b[39m     engine = \u001b[38;5;28mself\u001b[39m.create_engine_connection()\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '..\\\\sql_queries\\\\queries.sql'"
     ]
    }
   ],
   "source": [
    "@task(name=\"etl_dataset\", retries=2, retry_delay_seconds=10)\n",
    "def task_generate_data(n_registros: int = 10000, params = {\"medico\": \"PSICOLOGÍA\",\"fechaini\": \"20230101\",\"fechafin\": \"20250504\"}, \n",
    "                       sql_path = os.path.join(\"..\", \"..\", \"sql_queries\", \"queries.sql\")) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate synthetic user data for training.\n",
    "    \n",
    "    Args:\n",
    "        n_registros: Number of registros to generate\n",
    "        \n",
    "    Returns:\n",
    "        Generated dataframe\n",
    "    \"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(f\"Generating {n_registros} registros...\")\n",
    "    \n",
    "    # Generate data\n",
    "    sqlconection = SQLConnection(sql_path=sql_path, params=params)\n",
    "    df = sqlconection.generate_dataframe(n_registros)\n",
    "    df = EDAdataset(df)\n",
    "    df = df.dataset_eda(df)\n",
    "        \n",
    "    # Create summary artifact\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Metric': ['Total Samples', 'Total Features', 'Missing Values'],\n",
    "        'Value': [\n",
    "            len(df),\n",
    "            len(df.columns),\n",
    "            df.isnull().sum().sum()\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    create_table_artifact(\n",
    "        key=\"etl-dataframe-summary\",\n",
    "        table=summary_df.to_dict(orient='records'),\n",
    "        description=f\"ETL Data Generation Summary - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Generated {len(df)} samples with {len(df.columns)} columns\")\n",
    "    return df\n",
    "\n",
    "\n",
    "@task(name=\"Feature_Engineering\", retries=2, retry_delay_seconds=10)\n",
    "def task_feature_engineering(df, stopwords={\n",
    "            \"medico\", \"paciente\", \"psicologo\", \"psicologa\",\n",
    "            \"psicologia\", \"psicoterapeuta\", \"psicoterapia\", \"refiere\"\n",
    "        }, columna_texto=\"concatenada\", columna_sexo=\"sexo\", columna_grupo=\"grupo\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply feature engineering to the dataset.\n",
    "    \n",
    "    Args:\n",
    "        df: Input dataframe\n",
    "        \n",
    "    Returns:\n",
    "        Feature-engineered dataframe\n",
    "    \"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"Starting feature engineering...\")\n",
    "    \n",
    "    initial_columns = len(df.columns)\n",
    "    preprocesador = PreprocesadorTexto(df, stopwords=stopwords)\n",
    "    df_engineered, mapeos = preprocesador.procesar(columna_texto=columna_texto, columna_sexo=columna_sexo, columna_grupo=columna_grupo)\n",
    "    \n",
    "    # Create feature engineering summary\n",
    "    feature_summary = pd.DataFrame({\n",
    "        'Metric': ['Initial Features', 'Final Features', 'Features Added', 'Dataset Size', \"Mapeos Label Encodering\"],\n",
    "        'Value': [\n",
    "            initial_columns,\n",
    "            len(df_engineered.columns),\n",
    "            len(df_engineered.columns) - initial_columns,\n",
    "            f\"{len(df_engineered)} rows\",\n",
    "            mapeos\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    create_table_artifact(\n",
    "        key=\"feature-engineering-summary\",\n",
    "        table=feature_summary.to_dict(orient='records'),\n",
    "        description=\"Feature Engineering Summary\"\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Feature engineering complete: {initial_columns} -> {len(df_engineered.columns)} features\")\n",
    "    return df_engineered\n",
    "\n",
    "\n",
    "@task(name=\"Train_Model_Optuna\", retries=1, retry_delay_seconds=30)\n",
    "def task_train_with_optuna(\n",
    "    df: pd.DataFrame,\n",
    "    model_type: str = \"LogisticRegression\",\n",
    "    n_trials: int = 20,\n",
    "    optimization_metric: str = \"accuracy\"\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Train model with Optuna hyperparameter optimization and MLflow tracking.\n",
    "    \n",
    "    Args:\n",
    "        df: Feature-engineered dataframe\n",
    "        model_type: Type of model to train ('LogisticRegression' or 'RandomForest')\n",
    "        n_trials: Number of Optuna trials\n",
    "        optimization_metric: Metric to optimize\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (best_pipeline, best_run_id, study, metrics_dict)\n",
    "    \"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(f\"Starting Optuna optimization for {model_type} with {n_trials} trials...\")\n",
    "    \n",
    "    # Define Training Columns\n",
    "    training_columns = [\"concatenada\", \"sexo_codificado\"]\n",
    "    \n",
    "    # Define target column\n",
    "    target_column = 'grupo_codificado'\n",
    "    \n",
    "    # Define parameter distributions based on model type\n",
    "    if model_type == \"LogisticRegression\":\n",
    "        model_class = LogisticRegression\n",
    "        param_distributions = {\n",
    "            'C': ('float', 0.001, 100, True),\n",
    "            'penalty': ('categorical', ['l1', 'l2']),\n",
    "            'max_iter': ('int', 200, 2000),\n",
    "            'solver': ('categorical', ['liblinear', 'saga'])\n",
    "        }\n",
    "        fixed_params = {'random_state': 42}\n",
    "    elif model_type == \"RandomForest\":\n",
    "        model_class = RandomForestClassifier\n",
    "        param_distributions = {\n",
    "            'n_estimators': ('int', 50, 200),\n",
    "            'max_depth': ('int', 5, 30),\n",
    "            'min_samples_split': ('int', 2, 15),\n",
    "            'min_samples_leaf': ('int', 1, 10),\n",
    "            'max_features': ('categorical', ['sqrt', 'log2'])\n",
    "        }\n",
    "        fixed_params = {'random_state': 42, 'n_jobs': -1}\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    # Set up MLflow\n",
    "    mlflow.set_experiment(f\"prefect_{model_type.lower()}_training\")\n",
    "    mlflow.sklearn.autolog()\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = TrainMlflowOptuna(\n",
    "        df=df,\n",
    "        target_column=target_column,\n",
    "        model_class=model_class,\n",
    "        test_size=0.3,\n",
    "        n_trials=n_trials,\n",
    "        optimization_metric=optimization_metric,\n",
    "        param_distributions=param_distributions,\n",
    "        model_params=fixed_params\n",
    "    )\n",
    "    \n",
    "    # Run optimization\n",
    "    best_pipeline, best_run_id, study = trainer.train()\n",
    "    \n",
    "    # Create Optuna trials table artifact\n",
    "    trials_data = []\n",
    "    for trial in study.trials:\n",
    "        trials_data.append({\n",
    "            'Trial': trial.number,\n",
    "            'Value': f\"{trial.value:.4f}\" if trial.value else \"Failed\",\n",
    "            'State': trial.state.name,\n",
    "            'Duration (s)': f\"{(trial.datetime_complete - trial.datetime_start).total_seconds():.2f}\" \n",
    "                           if trial.datetime_complete else \"N/A\",\n",
    "            'Parameters': json.dumps(trial.params, indent=2)[:100] + \"...\"  # Truncate for display\n",
    "        })\n",
    "    \n",
    "    trials_df = pd.DataFrame(trials_data)\n",
    "    \n",
    "    create_table_artifact(\n",
    "        key=\"optuna-trials-summary\",\n",
    "        table=trials_df.head(10).to_dict(orient='records'),  # Show top 10 trials\n",
    "        description=f\"Optuna Optimization Results - {model_type} - Best {optimization_metric}: {study.best_value:.4f}\"\n",
    "    )\n",
    "    \n",
    "    # Create best parameters artifact\n",
    "    best_params_df = pd.DataFrame([\n",
    "        {'Parameter': k, 'Value': v} for k, v in study.best_params.items()\n",
    "    ])\n",
    "    \n",
    "    create_table_artifact(\n",
    "        key=\"best-hyperparameters\",\n",
    "        table=best_params_df.to_dict(orient='records'),\n",
    "        description=f\"Best Hyperparameters for {model_type}\"\n",
    "    )\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    X_test = df[training_columns][:100]  # Sample for quick validation\n",
    "    y_test = df[target_column][:100]\n",
    "    y_pred = best_pipeline.predict(X_test)\n",
    "    \n",
    "    metrics_dict = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "        'recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "        'f1': f1_score(y_test, y_pred, average='weighted')\n",
    "    }\n",
    "    \n",
    "    logger.info(f\"Optimization complete! Best {optimization_metric}: {study.best_value:.4f}\")\n",
    "    logger.info(f\"Best parameters: {study.best_params}\")\n",
    "    logger.info(f\"MLflow Run ID: {best_run_id}\")\n",
    "    \n",
    "    return best_pipeline, best_run_id, study, metrics_dict\n",
    "\n",
    "\n",
    "@task(name=\"Create_Model_Report\", retries=1)\n",
    "def task_create_model_report(\n",
    "    model_type: str,\n",
    "    best_run_id: str,\n",
    "    study,\n",
    "    metrics_dict: dict,\n",
    "    n_trials: int\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create comprehensive model training report as markdown artifact.\n",
    "    \n",
    "    Args:\n",
    "        model_type: Type of model trained\n",
    "        best_run_id: MLflow run ID\n",
    "        study: Optuna study object\n",
    "        metrics_dict: Dictionary of validation metrics\n",
    "        n_trials: Number of trials performed\n",
    "    \"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"Creating model training report...\")\n",
    "    \n",
    "    # Create markdown report\n",
    "    markdown_content = f\"\"\"\n",
    "# Model Training Report - {model_type}\n",
    "\n",
    "## Training Summary\n",
    "- **Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "- **Model Type**: {model_type}\n",
    "- **Number of Trials**: {n_trials}\n",
    "- **MLflow Run ID**: `{best_run_id}`\n",
    "\n",
    "## Optimization Results\n",
    "- **Best Score**: {study.best_value:.4f}\n",
    "- **Optimization Metric**: {study.trials[0].user_attrs.get('metric_name', 'accuracy') if study.trials else 'N/A'}\n",
    "- **Total Trials Completed**: {len([t for t in study.trials if t.state.name == 'COMPLETE'])}\n",
    "\n",
    "## Best Hyperparameters\n",
    "```python\n",
    "{json.dumps(study.best_params, indent=2)}\n",
    "```\n",
    "\n",
    "## Validation Metrics\n",
    "| Metric | Score |\n",
    "|--------|-------|\n",
    "| Accuracy | {metrics_dict['accuracy']:.4f} |\n",
    "| Precision | {metrics_dict['precision']:.4f} |\n",
    "| Recall | {metrics_dict['recall']:.4f} |\n",
    "| F1 Score | {metrics_dict['f1']:.4f} |\n",
    "\n",
    "## Top 5 Trials\n",
    "| Trial | Score | Parameters |\n",
    "|-------|-------|------------|\n",
    "\"\"\"\n",
    "    \n",
    "    # Add top 5 trials\n",
    "    sorted_trials = sorted(study.trials, key=lambda t: t.value if t.value else 0, reverse=True)[:5]\n",
    "    for trial in sorted_trials:\n",
    "        if trial.value:\n",
    "            params_str = ', '.join([f\"{k}={v}\" for k, v in list(trial.params.items())[:3]])\n",
    "            markdown_content += f\"| {trial.number} | {trial.value:.4f} | {params_str}... |\\n\"\n",
    "    \n",
    "    markdown_content += f\"\"\"\n",
    "\n",
    "## How to Use the Model\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "# Load the best model\n",
    "model = mlflow.sklearn.load_model(f\"runs:/{best_run_id}/model\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_new)\n",
    "```\n",
    "\n",
    "## Next Steps\n",
    "1. Review the model performance in MLflow UI\n",
    "2. Deploy the model if metrics meet requirements\n",
    "3. Monitor model performance in production\n",
    "\"\"\"\n",
    "    \n",
    "    create_markdown_artifact(\n",
    "        key=\"model-training-report\",\n",
    "        markdown=markdown_content,\n",
    "        description=f\"Complete Training Report for {model_type}\"\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Model training report created successfully\")\n",
    "\n",
    "\n",
    "@flow(name=\"Train_Model_With_Optuna\", log_prints=True)\n",
    "def train_model_flow(\n",
    "    n_registros: int = 10000,\n",
    "    model_type: str = \"LogisticRegression\",\n",
    "    n_trials: int = 20,\n",
    "    optimization_metric: str = \"accuracy\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Main Prefect flow for training models with Optuna optimization.\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Number of samples to generate\n",
    "        model_type: Type of model to train\n",
    "        n_trials: Number of Optuna trials\n",
    "        optimization_metric: Metric to optimize\n",
    "        \n",
    "    Returns:\n",
    "        Trained pipeline and MLflow run ID\n",
    "    \"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(f\"Starting training flow for {model_type}\")\n",
    "    \n",
    "    # Task 1: Generate data\n",
    "    df = task_generate_data(n_registros=n_registros)\n",
    "    \n",
    "    # Task 2: Feature engineering\n",
    "    df_engineered = task_feature_engineering(df)\n",
    "    \n",
    "    # Task 3: Train with Optuna\n",
    "    best_pipeline, best_run_id, study, metrics_dict = task_train_with_optuna(\n",
    "        df_engineered,\n",
    "        model_type,\n",
    "        n_trials,\n",
    "        optimization_metric\n",
    "    )\n",
    "    \n",
    "    # Task 4: Create report\n",
    "    task_create_model_report(\n",
    "        model_type,\n",
    "        best_run_id,\n",
    "        study,\n",
    "        metrics_dict,\n",
    "        n_trials\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Training flow complete! Best model saved with run ID: {best_run_id}\")\n",
    "    \n",
    "    # Create final summary artifact\n",
    "    final_summary = pd.DataFrame({\n",
    "        'Metric': ['Model Type', 'Best Score', 'MLflow Run ID', 'Total Time'],\n",
    "        'Value': [\n",
    "            model_type,\n",
    "            f\"{study.best_value:.4f}\",\n",
    "            best_run_id,\n",
    "            f\"{sum((t.datetime_complete - t.datetime_start).total_seconds() for t in study.trials if t.datetime_complete):.2f}s\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    create_table_artifact(\n",
    "        key=\"training-flow-summary\",\n",
    "        table=final_summary.to_dict(orient='records'),\n",
    "        description=\"Final Training Flow Summary\"\n",
    "    )\n",
    "    \n",
    "    return best_pipeline, best_run_id\n",
    "\n",
    "\n",
    "@flow(name=\"Compare_Models\", log_prints=True)\n",
    "def compare_models_flow(\n",
    "    n_registros: int = 10000,\n",
    "    n_trials: int = 15\n",
    "):\n",
    "    \"\"\"\n",
    "    Flow to compare multiple models with Optuna optimization.\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Number of samples to generate\n",
    "        n_trials: Number of Optuna trials per model\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with results for each model\n",
    "    \"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"Starting model comparison flow...\")\n",
    "    \n",
    "    # Generate data once\n",
    "    df = task_generate_data(n_registros=n_registros)\n",
    "    df_engineered = task_feature_engineering(df)\n",
    "    \n",
    "    results = {}\n",
    "    models_to_compare = [\"LogisticRegression\", \"RandomForest\"]\n",
    "    metrics_to_try = [\"accuracy\", \"f1\"]\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    for model_type in models_to_compare:\n",
    "        for metric in metrics_to_try:\n",
    "            logger.info(f\"Training {model_type} optimizing for {metric}...\")\n",
    "            \n",
    "            best_pipeline, best_run_id, study, metrics_dict = task_train_with_optuna(\n",
    "                df_engineered,\n",
    "                model_type,\n",
    "                n_trials,\n",
    "                metric\n",
    "            )\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'Model': model_type,\n",
    "                'Optimization Metric': metric,\n",
    "                'Best Score': f\"{study.best_value:.4f}\",\n",
    "                'Accuracy': f\"{metrics_dict['accuracy']:.4f}\",\n",
    "                'F1 Score': f\"{metrics_dict['f1']:.4f}\",\n",
    "                'MLflow Run ID': best_run_id[:8] + \"...\"\n",
    "            })\n",
    "            \n",
    "            results[f\"{model_type}_{metric}\"] = {\n",
    "                'pipeline': best_pipeline,\n",
    "                'run_id': best_run_id,\n",
    "                'best_score': study.best_value\n",
    "            }\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    create_table_artifact(\n",
    "        key=\"model-comparison-results\",\n",
    "        table=comparison_df.to_dict(orient='records'),\n",
    "        description=\"Model Comparison Results - Multiple Models and Metrics\"\n",
    "    )\n",
    "    \n",
    "    # Find best overall model\n",
    "    best_model_key = max(results.keys(), key=lambda k: results[k]['best_score'])\n",
    "    \n",
    "    logger.info(f\"Model comparison complete! Best model: {best_model_key}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: Train a single model\n",
    "    pipeline, run_id = train_model_flow(\n",
    "        n_registros=5000,\n",
    "        model_type=\"LogisticRegression\",\n",
    "        n_trials=10,\n",
    "        optimization_metric=\"accuracy\"\n",
    "    )\n",
    "    \n",
    "    # Example 2: Compare multiple models\n",
    "    # results = compare_models_flow(n_samples=5000, n_trials=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proyecto_Final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
